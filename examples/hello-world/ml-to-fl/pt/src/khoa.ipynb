{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.combine import SMOTETomek \n",
    "\n",
    "class FraudDataset(Dataset):\n",
    "    \"\"\"Custom PyTorch Dataset for Fraud Detection\"\"\"\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "def check_data_leakage(X_train, X_valid, X_test):\n",
    "    train_df = pd.DataFrame(X_train)\n",
    "    valid_df = pd.DataFrame(X_valid)\n",
    "    test_df = pd.DataFrame(X_test)\n",
    "\n",
    "    overlap_train_test = test_df.merge(train_df, how=\"inner\")\n",
    "    overlap_train_valid = test_df.merge(valid_df, how=\"inner\")\n",
    "\n",
    "    print(f\"Overlapping samples between Train & Test: {len(overlap_train_test)}\")\n",
    "    print(f\"Overlapping samples between Validation & Test: {len(overlap_train_valid)}\")\n",
    "\n",
    "\n",
    "def add_noise(X_train, mean=0, sigma=0.1):\n",
    "    \"\"\"\n",
    "    Adds Gaussian noise to the training data.\n",
    "    Args:\n",
    "        X_train (numpy array): Training features.\n",
    "        mean (float): Mean of Gaussian noise.\n",
    "        sigma (float): Standard deviation of noise.\n",
    "\n",
    "    Returns:\n",
    "        numpy array: Noisy training features.\n",
    "    \"\"\"\n",
    "    noise = np.random.normal(mean, sigma, X_train.shape)\n",
    "    return X_train + noise\n",
    "\n",
    "def get_dataloaders_fraud(csv_path, batch_size=64, num_workers=0, validation_fraction=0.2, use_smote=True, add_noise_flag=True, noise_std=0.1):\n",
    "    \"\"\"\n",
    "    Load fraud detection dataset from CSV, apply SMOTE if needed, add Gaussian noise, and create DataLoaders.\n",
    "    \n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file.\n",
    "        batch_size (int): Number of samples per batch.\n",
    "        num_workers (int): Number of workers for DataLoader.\n",
    "        validation_fraction (float): Fraction of training data to use for validation.\n",
    "        use_smote (bool): Whether to apply SMOTE to balance the dataset.\n",
    "        add_noise_flag (bool): Whether to add Gaussian noise after SMOTE.\n",
    "        noise_std (float): Standard deviation of Gaussian noise.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_loader, valid_loader, test_loader, class_weights, y_train_before, y_train)\n",
    "    \"\"\"\n",
    "    # Load dataset from CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Extract features & labels\n",
    "    X = df.drop(columns=['Class']).values  \n",
    "    y = df['Class'].values  \n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Compute class weights\n",
    "    class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y), y=y.tolist())\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float32)  # Convert to PyTorch tensor\n",
    "\n",
    "    # Split into train (80%) and test (20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    y_train_before = y_train.copy()  # Store original train labels for reference\n",
    "\n",
    "    \n",
    "    # Apply SMOTE only to training set\n",
    "    if use_smote:\n",
    "        print(\"Applying SMOTE to balance training data...\")\n",
    "        smote = SMOTETomek(sampling_strategy=0.4, random_state=42)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # **Add Gaussian Noise to Training Data (After SMOTE)**\n",
    "    if add_noise_flag:\n",
    "        print(f\"Adding Gaussian noise (std={noise_std}) to training data...\")\n",
    "        X_train = add_noise(X_train, sigma=noise_std)  # Add noise\n",
    "\n",
    "    # Further split train into train (80%) and validation (20%) if validation_fraction > 0\n",
    "    # Split further into train & validation if validation_fraction > 0\n",
    "    if validation_fraction > 0:\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "            X_train, y_train, test_size=validation_fraction, stratify=y_train, random_state=42\n",
    "        )\n",
    "    else:\n",
    "        X_valid, y_valid = None, None  # Assign None to avoid UnboundLocalError\n",
    "\n",
    "    # Ensure variables exist before calling check_data_leakage()\n",
    "    if X_valid is not None and X_test is not None:\n",
    "        check_data_leakage(X_train, X_valid, X_test)\n",
    "\n",
    "\n",
    "    # Convert labels to PyTorch-compatible integer format (no one-hot encoding)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "    if X_valid is not None:\n",
    "        y_valid = torch.tensor(y_valid, dtype=torch.float32)\n",
    "\n",
    "    # Create PyTorch Datasets\n",
    "    train_dataset = FraudDataset(X_train, y_train)\n",
    "    test_dataset = FraudDataset(X_test, y_test)\n",
    "    \n",
    "    if X_valid is not None:\n",
    "        valid_dataset = FraudDataset(X_valid, y_valid)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "    else:\n",
    "        valid_loader = None\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
    "\n",
    "    print(f\"Training set size after SMOTE: {len(train_dataset)} samples\")\n",
    "    print(f\"Test set size: {len(test_dataset)} samples\")\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "def compute_metrics(model, data_loader, device, apply_mask=False):\n",
    "    \"\"\"\n",
    "    Compute accuracy, precision, recall, F1-score, and AUC-ROC for a fraud detection model.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_predictions, all_targets, all_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, targets in data_loader:\n",
    "            features, targets = features.to(device), targets.to(device)\n",
    "            targets = targets.view(-1).cpu().numpy()\n",
    "\n",
    "            logits = model(features, apply_mask=apply_mask)\n",
    "            probabilities = torch.sigmoid(logits).cpu().numpy().flatten()\n",
    "            predictions = (probabilities >= 0.5).astype(int)  # Fix: Lowered threshold to 0.5\n",
    "\n",
    "            all_predictions.extend(predictions)\n",
    "            all_targets.extend(targets)\n",
    "            all_probs.extend(probabilities)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(all_targets, all_predictions) * 100,\n",
    "        \"precision\": precision_score(all_targets, all_predictions, zero_division=0) * 100,\n",
    "        \"recall\": recall_score(all_targets, all_predictions, zero_division=0) * 100,\n",
    "        \"f1_score\": f1_score(all_targets, all_predictions, zero_division=0) * 100,\n",
    "        \"auc_roc\": roc_auc_score(all_targets, all_probs) * 100,\n",
    "        \"auc_pr\": average_precision_score(all_targets, all_probs) * 100\n",
    "        \n",
    "    }\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test dataset and print key metrics.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained model to evaluate.\n",
    "        test_loader (torch.utils.data.DataLoader): DataLoader for the test dataset.\n",
    "        device (torch.device): Device ('cpu' or 'cuda') to perform computations.\n",
    "    \"\"\"\n",
    "    metrics = compute_metrics(model, test_loader, device)\n",
    "\n",
    "    print(\"**Evaluation Results:**\")\n",
    "    print(f\"Accuracy   : {metrics['accuracy']:.2f}%\")\n",
    "    print(f\"Precision  : {metrics['precision']:.2f}%\")\n",
    "    print(f\"Recall     : {metrics['recall']:.2f}%\")\n",
    "    print(f\"F1-score   : {metrics['f1_score']:.2f}%\")\n",
    "    print(f\"AUC-ROC    : {metrics['auc_roc']:.2f}%\")  # New metric\n",
    "    print(f\"AUC-PR    : {metrics['auc_pr']:.2f}%\")  # New metric\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2023, NVIDIA CORPORATION.  All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "#         self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "#         self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "    \n",
    "class FraudNet(nn.Module):\n",
    "    def __init__(self, input_size, dropout_rate=0.6):\n",
    "        \"\"\"\n",
    "        A fully connected neural network (MLP) for fraud detection.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Number of features in the dataset.\n",
    "            dropout_rate (float): Dropout probability for regularization.\n",
    "        \"\"\"\n",
    "        super(FraudNet, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.fc4 = nn.Linear(32, 1)  # Binary classification output (logits)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # Placeholder for stochastic dropout masks\n",
    "        self.dense_mask = None\n",
    "\n",
    "    def forward(self, x, apply_mask=False):\n",
    "        \"\"\"\n",
    "        Forward pass through the fraud detection model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input features.\n",
    "            apply_mask (bool, optional): Whether to apply a dropout mask for Federated Learning. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Logits for binary classification (sigmoid will be applied in loss function).\n",
    "        \"\"\"\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "\n",
    "        # if apply_mask and self.dense_mask is not None:\n",
    "        #     self.dense_mask = self.dense_mask.to(x.device)\n",
    "        #     x = x * self.dense_mask\n",
    "        #     x = x / (1 - self.dropout_rate)  # Normalize output\n",
    "\n",
    "        x = self.fc4(x)  # No sigmoid here! BCEWithLogitsLoss expects raw logits\n",
    "        return x\n",
    "\n",
    "    def resample_dropout_masks(self, x):\n",
    "        \"\"\"\n",
    "        Resample dropout mask for fully connected layers (used in Stochastic Dropout).\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "        \"\"\"\n",
    "        self.dense_mask = torch.bernoulli(torch.ones(self.fc3.out_features) * (1 - self.dropout_rate)).to(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from distutils.version import LooseVersion as Version\n",
    "from nvflare.client.tracking import SummaryWriter\n",
    "from evaluation import compute_metrics  # Call evaluation function only\n",
    "from data import get_dataloaders_fraud  # Import dataset functions\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    \"\"\"Set seed to ensure reproducibility.\"\"\"\n",
    "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def set_deterministic():\n",
    "    \"\"\"Enable deterministic mode to ensure stable results.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    if torch.__version__ <= Version(\"1.7\"):\n",
    "        torch.set_deterministic(True)\n",
    "    else:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "\n",
    "def train_model(model, num_epochs, train_loader, valid_loader, test_loader, \n",
    "                optimizer, criterion, device, input_model=None, summary_writer=None, \n",
    "                scheduler=None, stochastic=False, early_stopping_patience=10):\n",
    "    \"\"\"\n",
    "    Trains the fraud detection model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to train.\n",
    "        num_epochs (int): Number of training epochs.\n",
    "        train_loader (DataLoader): DataLoader for training data.\n",
    "        valid_loader (DataLoader): DataLoader for validation data.\n",
    "        test_loader (DataLoader): DataLoader for test data.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer for model training.\n",
    "        criterion (torch.nn.Module): Loss function.\n",
    "        device (torch.device): Device to run the model ('cuda' or 'cpu').\n",
    "        scheduler (torch.optim.lr_scheduler, optional): Learning rate scheduler.\n",
    "        early_stopping_patience (int): Number of epochs to wait before stopping if validation loss does not improve.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Lists of training loss, training accuracy, validation accuracy, and final test metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    minibatch_loss_list, train_metrics_list, valid_metrics_list = [], [], []\n",
    "    best_valid_f1 = 0.0  # Track Best F1-score\n",
    "    patience_counter = 0  # Track early stopping criteria\n",
    "    \n",
    "    if summary_writer is not None:\n",
    "        summary_writer = SummaryWriter()\n",
    "\n",
    "    print(\"Starting Training...\")\n",
    "    # log_interval = 500  # Adjust log interval for fraud dataset\n",
    "    log_interval = max(10, len(train_loader) // 10)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if stochastic:\n",
    "            model.resample_dropout_masks(next(iter(train_loader))[0])\n",
    "        model.train()\n",
    "        \n",
    "        total_loss = 0\n",
    "        for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "            features, targets = features.to(device), targets.to(device)\n",
    "            targets = targets.view(-1, 1)  \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(features, apply_mask=True)\n",
    "            loss = criterion(logits, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            minibatch_loss_list.append(loss.item())\n",
    "\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print(f\"[Epoch {epoch + 1}, Batch {batch_idx + 1}] Loss: {loss:.4f}\")\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # Evaluate the model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_metrics = compute_metrics(model, valid_loader, device)\n",
    "            train_metrics = compute_metrics(model, train_loader, device)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}: \"\n",
    "                  f\"Train Acc: {train_metrics['accuracy']:.2f}% | \"\n",
    "                  f\"Valid Acc: {valid_metrics['accuracy']:.2f}% | \"\n",
    "                  f\"Valid Precision: {valid_metrics['precision']:.2f}% | \"\n",
    "                  f\"Valid Recall: {valid_metrics['recall']:.2f}% | \"\n",
    "                  f\"Valid F1-score: {valid_metrics['f1_score']:.2f}% | \"\n",
    "                  f\"Valid AUC-PR: {valid_metrics['auc_pr']:.2f}%\")\n",
    "\n",
    "            train_metrics_list.append(train_metrics)\n",
    "            valid_metrics_list.append(valid_metrics)\n",
    "\n",
    "        elapsed = (time.time() - start_time)/60\n",
    "        print(f\"Time Elapsed: {elapsed:.2f} minutes\")\n",
    "\n",
    "        # Early Stopping Check (Using F1-score)\n",
    "        if valid_metrics['f1_score'] > best_valid_f1:\n",
    "            best_valid_f1 = valid_metrics['f1_score']\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            print(\"Model improved. Saving best model.\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(\"Early stopping triggered. Training stopped.\")\n",
    "                break\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(valid_metrics['f1_score'])\n",
    "            \n",
    "    # Load the best model before testing\n",
    "    model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "    print(\"Evaluating best saved model on test data.\")\n",
    "\n",
    "    # Final Test Evaluation\n",
    "    test_metrics = compute_metrics(model, test_loader, device)\n",
    "    print(f\"**Final Test Results:** \"\n",
    "          f\"Accuracy: {test_metrics['accuracy']:.2f}%, \"\n",
    "          f\"Precision: {test_metrics['precision']:.2f}%, \"\n",
    "          f\"Recall: {test_metrics['recall']:.2f}%, \"\n",
    "          f\"F1-score: {test_metrics['f1_score']:.2f}%, \"\n",
    "          f\"AUC-PR: {test_metrics['auc_pr']:.2f}%\")\n",
    "\n",
    "    return minibatch_loss_list, train_metrics_list, valid_metrics_list, test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying SMOTE to balance training data...\n",
      "Adding Gaussian noise (std=0.1) to training data...\n",
      "Overlapping samples between Train & Test: 0\n",
      "Overlapping samples between Validation & Test: 0\n",
      "Training set size after SMOTE: 254744 samples\n",
      "Test set size: 56962 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khoa/Khoa/outsource/na_thesis/examples/hello-world/ml-to-fl/pt/src/data.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.labels = torch.tensor(labels, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected input size: 30\n",
      "Starting Training...\n",
      "[Epoch 1, Batch 1] Loss: 0.6867\n",
      "[Epoch 1, Batch 399] Loss: 0.1904\n",
      "[Epoch 1, Batch 797] Loss: 0.0958\n",
      "[Epoch 1, Batch 1195] Loss: 0.0426\n",
      "[Epoch 1, Batch 1593] Loss: 0.0446\n",
      "[Epoch 1, Batch 1991] Loss: 0.0451\n",
      "[Epoch 1, Batch 2389] Loss: 0.0734\n",
      "[Epoch 1, Batch 2787] Loss: 0.0613\n",
      "[Epoch 1, Batch 3185] Loss: 0.0852\n",
      "[Epoch 1, Batch 3583] Loss: 0.0832\n",
      "[Epoch 1, Batch 3981] Loss: 0.2263\n",
      "Epoch 1/10: Train Acc: 98.05% | Valid Acc: 98.05% | Valid Precision: 98.40% | Valid Recall: 94.73% | Valid F1-score: 96.53% | Valid AUC-PR: 99.55%\n",
      "Time Elapsed: 0.24 minutes\n",
      "Model improved. Saving best model.\n",
      "[Epoch 2, Batch 1] Loss: 0.0351\n",
      "[Epoch 2, Batch 399] Loss: 0.0823\n",
      "[Epoch 2, Batch 797] Loss: 0.0282\n",
      "[Epoch 2, Batch 1195] Loss: 0.0472\n",
      "[Epoch 2, Batch 1593] Loss: 0.0519\n",
      "[Epoch 2, Batch 1991] Loss: 0.0407\n",
      "[Epoch 2, Batch 2389] Loss: 0.0493\n",
      "[Epoch 2, Batch 2787] Loss: 0.0865\n",
      "[Epoch 2, Batch 3185] Loss: 0.0697\n",
      "[Epoch 2, Batch 3583] Loss: 0.0128\n",
      "[Epoch 2, Batch 3981] Loss: 0.0026\n",
      "Epoch 2/10: Train Acc: 98.91% | Valid Acc: 98.86% | Valid Precision: 99.00% | Valid Recall: 96.99% | Valid F1-score: 97.98% | Valid AUC-PR: 99.83%\n",
      "Time Elapsed: 0.48 minutes\n",
      "Model improved. Saving best model.\n",
      "[Epoch 3, Batch 1] Loss: 0.0137\n",
      "[Epoch 3, Batch 399] Loss: 0.0512\n",
      "[Epoch 3, Batch 797] Loss: 0.1163\n",
      "[Epoch 3, Batch 1195] Loss: 0.0115\n",
      "[Epoch 3, Batch 1593] Loss: 0.0719\n",
      "[Epoch 3, Batch 1991] Loss: 0.0579\n",
      "[Epoch 3, Batch 2389] Loss: 0.0701\n",
      "[Epoch 3, Batch 2787] Loss: 0.0949\n",
      "[Epoch 3, Batch 3185] Loss: 0.1492\n",
      "[Epoch 3, Batch 3583] Loss: 0.1391\n",
      "[Epoch 3, Batch 3981] Loss: 0.0085\n",
      "Epoch 3/10: Train Acc: 99.19% | Valid Acc: 99.13% | Valid Precision: 98.34% | Valid Recall: 98.60% | Valid F1-score: 98.47% | Valid AUC-PR: 99.88%\n",
      "Time Elapsed: 0.72 minutes\n",
      "Model improved. Saving best model.\n",
      "[Epoch 4, Batch 1] Loss: 0.0282\n",
      "[Epoch 4, Batch 399] Loss: 0.0165\n",
      "[Epoch 4, Batch 797] Loss: 0.0166\n",
      "[Epoch 4, Batch 1195] Loss: 0.0697\n",
      "[Epoch 4, Batch 1593] Loss: 0.0393\n",
      "[Epoch 4, Batch 1991] Loss: 0.1516\n",
      "[Epoch 4, Batch 2389] Loss: 0.0534\n",
      "[Epoch 4, Batch 2787] Loss: 0.0713\n",
      "[Epoch 4, Batch 3185] Loss: 0.0164\n",
      "[Epoch 4, Batch 3583] Loss: 0.0080\n",
      "[Epoch 4, Batch 3981] Loss: 0.0858\n",
      "Epoch 4/10: Train Acc: 99.34% | Valid Acc: 99.28% | Valid Precision: 99.38% | Valid Recall: 98.09% | Valid F1-score: 98.73% | Valid AUC-PR: 99.92%\n",
      "Time Elapsed: 0.96 minutes\n",
      "Model improved. Saving best model.\n",
      "[Epoch 5, Batch 1] Loss: 0.0114\n",
      "[Epoch 5, Batch 399] Loss: 0.0670\n",
      "[Epoch 5, Batch 797] Loss: 0.0756\n",
      "[Epoch 5, Batch 1195] Loss: 0.0440\n",
      "[Epoch 5, Batch 1593] Loss: 0.0222\n",
      "[Epoch 5, Batch 1991] Loss: 0.0228\n",
      "[Epoch 5, Batch 2389] Loss: 0.0359\n",
      "[Epoch 5, Batch 2787] Loss: 0.0039\n",
      "[Epoch 5, Batch 3185] Loss: 0.0043\n",
      "[Epoch 5, Batch 3583] Loss: 0.0297\n",
      "[Epoch 5, Batch 3981] Loss: 0.0601\n",
      "Epoch 5/10: Train Acc: 99.49% | Valid Acc: 99.47% | Valid Precision: 98.97% | Valid Recall: 99.18% | Valid F1-score: 99.08% | Valid AUC-PR: 99.93%\n",
      "Time Elapsed: 1.19 minutes\n",
      "Model improved. Saving best model.\n",
      "[Epoch 6, Batch 1] Loss: 0.0191\n",
      "[Epoch 6, Batch 399] Loss: 0.0079\n",
      "[Epoch 6, Batch 797] Loss: 0.0564\n",
      "[Epoch 6, Batch 1195] Loss: 0.0136\n",
      "[Epoch 6, Batch 1593] Loss: 0.0062\n",
      "[Epoch 6, Batch 1991] Loss: 0.0300\n",
      "[Epoch 6, Batch 2389] Loss: 0.0273\n",
      "[Epoch 6, Batch 2787] Loss: 0.1117\n",
      "[Epoch 6, Batch 3185] Loss: 0.0299\n",
      "[Epoch 6, Batch 3583] Loss: 0.0212\n",
      "[Epoch 6, Batch 3981] Loss: 0.0317\n",
      "Epoch 6/10: Train Acc: 99.58% | Valid Acc: 99.57% | Valid Precision: 99.30% | Valid Recall: 99.21% | Valid F1-score: 99.25% | Valid AUC-PR: 99.94%\n",
      "Time Elapsed: 1.43 minutes\n",
      "Model improved. Saving best model.\n",
      "[Epoch 7, Batch 1] Loss: 0.0186\n",
      "[Epoch 7, Batch 399] Loss: 0.0254\n",
      "[Epoch 7, Batch 797] Loss: 0.0074\n",
      "[Epoch 7, Batch 1195] Loss: 0.0282\n",
      "[Epoch 7, Batch 1593] Loss: 0.0111\n",
      "[Epoch 7, Batch 1991] Loss: 0.0208\n",
      "[Epoch 7, Batch 2389] Loss: 0.0398\n",
      "[Epoch 7, Batch 2787] Loss: 0.2006\n",
      "[Epoch 7, Batch 3185] Loss: 0.0445\n",
      "[Epoch 7, Batch 3583] Loss: 0.0501\n",
      "[Epoch 7, Batch 3981] Loss: 0.1257\n",
      "Epoch 7/10: Train Acc: 99.67% | Valid Acc: 99.66% | Valid Precision: 99.35% | Valid Recall: 99.46% | Valid F1-score: 99.41% | Valid AUC-PR: 99.96%\n",
      "Time Elapsed: 1.67 minutes\n",
      "Model improved. Saving best model.\n",
      "[Epoch 8, Batch 1] Loss: 0.0128\n",
      "[Epoch 8, Batch 399] Loss: 0.0936\n",
      "[Epoch 8, Batch 797] Loss: 0.0055\n",
      "[Epoch 8, Batch 1195] Loss: 0.0031\n",
      "[Epoch 8, Batch 1593] Loss: 0.0261\n",
      "[Epoch 8, Batch 1991] Loss: 0.0073\n",
      "[Epoch 8, Batch 2389] Loss: 0.0125\n",
      "[Epoch 8, Batch 2787] Loss: 0.0066\n",
      "[Epoch 8, Batch 3185] Loss: 0.0097\n",
      "[Epoch 8, Batch 3583] Loss: 0.0418\n",
      "[Epoch 8, Batch 3981] Loss: 0.0598\n",
      "Epoch 8/10: Train Acc: 99.63% | Valid Acc: 99.62% | Valid Precision: 99.44% | Valid Recall: 99.23% | Valid F1-score: 99.33% | Valid AUC-PR: 99.97%\n",
      "Time Elapsed: 1.97 minutes\n",
      "[Epoch 9, Batch 1] Loss: 0.0254\n",
      "[Epoch 9, Batch 399] Loss: 0.0149\n",
      "[Epoch 9, Batch 797] Loss: 0.0187\n",
      "[Epoch 9, Batch 1195] Loss: 0.0309\n",
      "[Epoch 9, Batch 1593] Loss: 0.0024\n",
      "[Epoch 9, Batch 1991] Loss: 0.0065\n",
      "[Epoch 9, Batch 2389] Loss: 0.0030\n",
      "[Epoch 9, Batch 2787] Loss: 0.0212\n",
      "[Epoch 9, Batch 3185] Loss: 0.0063\n",
      "[Epoch 9, Batch 3583] Loss: 0.0253\n",
      "[Epoch 9, Batch 3981] Loss: 0.1574\n",
      "Epoch 9/10: Train Acc: 99.62% | Valid Acc: 99.63% | Valid Precision: 99.24% | Valid Recall: 99.48% | Valid F1-score: 99.36% | Valid AUC-PR: 99.96%\n",
      "Time Elapsed: 2.21 minutes\n",
      "[Epoch 10, Batch 1] Loss: 0.0080\n",
      "[Epoch 10, Batch 399] Loss: 0.0169\n",
      "[Epoch 10, Batch 797] Loss: 0.0480\n",
      "[Epoch 10, Batch 1195] Loss: 0.0097\n",
      "[Epoch 10, Batch 1593] Loss: 0.0144\n",
      "[Epoch 10, Batch 1991] Loss: 0.0022\n",
      "[Epoch 10, Batch 2389] Loss: 0.0092\n",
      "[Epoch 10, Batch 2787] Loss: 0.0620\n",
      "[Epoch 10, Batch 3185] Loss: 0.0714\n",
      "[Epoch 10, Batch 3583] Loss: 0.0703\n",
      "[Epoch 10, Batch 3981] Loss: 0.0005\n",
      "Epoch 10/10: Train Acc: 99.72% | Valid Acc: 99.72% | Valid Precision: 99.47% | Valid Recall: 99.55% | Valid F1-score: 99.51% | Valid AUC-PR: 99.96%\n",
      "Time Elapsed: 2.42 minutes\n",
      "Model improved. Saving best model.\n",
      "Evaluating best saved model on test data.\n",
      "**Final Test Results:** Accuracy: 99.70%, Precision: 35.10%, Recall: 87.76%, F1-score: 50.15%, AUC-PR: 83.76%\n",
      "Loaded best model from training phase.\n",
      "Final best model saved explicitly at ./best_fraud_model.pth\n",
      "Evaluating Model on Test Set...\n",
      "**Evaluation Results:**\n",
      "Accuracy   : 99.70%\n",
      "Precision  : 35.10%\n",
      "Recall     : 87.76%\n",
      "F1-score   : 50.15%\n",
      "AUC-ROC    : 97.39%\n",
      "AUC-PR    : 83.76%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 99.69979986657772,\n",
       " 'precision': 35.10204081632653,\n",
       " 'recall': 87.75510204081633,\n",
       " 'f1_score': 50.14577259475219,\n",
       " 'auc_roc': 97.39326125779517,\n",
       " 'auc_pr': 83.75772697681137}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from net import FraudNet  # Import fraud detection model\n",
    "import pandas as pd\n",
    "\n",
    "# Set dataset path\n",
    "DATASET_PATH = \"data/creditcard.csv\"\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Training hyperparameters\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "learning_rate = 0.0003\n",
    "\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_dataloaders_fraud(\n",
    "    DATASET_PATH, batch_size=batch_size, use_smote=True\n",
    ")\n",
    "\n",
    "# Dynamically determine input size from dataset\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "input_size = df.shape[1] - 1  \n",
    "print(f\"Detected input size: {input_size}\")\n",
    "\n",
    "# Initialize Model\n",
    "model = FraudNet(input_size=input_size).to(DEVICE)\n",
    "\n",
    "# Loss Function (No weight balancing since using SMOTE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Call `train.py` instead of writing the training loop here\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "optimizer, mode='max', patience=3, verbose=True\n",
    ")\n",
    "\n",
    "train_loss_list, train_metrics_list, valid_metrics_list, test_metrics = train_model(\n",
    "    model, num_epochs, train_loader, valid_loader, test_loader, optimizer,\n",
    "    criterion, DEVICE, scheduler=scheduler , stochastic=False\n",
    ")\n",
    "\n",
    "# plot...\n",
    "\n",
    "# Save the trained model\n",
    "best_model_path = \"best_model.pth\"\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "print(\"Loaded best model from training phase.\")\n",
    "\n",
    "# Save the best model explicitly at a clear location for future usage\n",
    "final_model_path = \"./best_fraud_model.pth\"\n",
    "torch.save(model.state_dict(), best_model_path)\n",
    "print(f\"Final best model saved explicitly at {final_model_path}\")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"Evaluating Model on Test Set...\")\n",
    "evaluate_model(model, test_loader, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-18.345982]\n",
      " [-18.234858]\n",
      " [-15.488237]\n",
      " ...\n",
      " [-19.943556]\n",
      " [-17.315147]\n",
      " [-10.824679]]\n",
      "\n",
      "Confusion Matrix:\n",
      "[[56776    88]\n",
      " [   12    86]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "x_test = [x for x, y in test_loader]\n",
    "x_test_tensor = torch.cat(x_test, dim=0).cuda()\n",
    "y_test = [y for x, y in test_loader]\n",
    "\n",
    "y_test_tensor = torch.cat(y_test, dim=0)\n",
    "y_test_numpy = y_test_tensor.detach().cpu().numpy()\n",
    "\n",
    "# Get predictions from model\n",
    "with torch.no_grad():\n",
    "    predictions = model(x_test_tensor)\n",
    "    y_pred_numpy = predictions.detach().cpu().numpy()\n",
    "\n",
    "print(y_pred_numpy)\n",
    "y_pred_numpy = (y_pred_numpy > 0.999).astype(int)\n",
    "\n",
    "# Now both should be discrete class labels\n",
    "cm = confusion_matrix(y_test_numpy, y_pred_numpy)\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Visualize the confusion matrix (optional but recommended)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Class 0', 'Class 1'],\n",
    "            yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 99.69979986657772, 'precision': 35.10204081632653, 'recall': 87.75510204081633, 'f1_score': 50.14577259475219, 'auc_roc': 97.39326125779517, 'auc_pr': 83.75772697681137}\n"
     ]
    }
   ],
   "source": [
    "print(test_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "khoa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
